{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TattooeDeer/2DSPP/blob/master/Teacher_training_modif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpRgIYcmuNc7",
        "outputId": "d812f5f8-99b8-467c-f0c5-e6627c849d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hdbscan\n",
            "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 7.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.8/dist-packages (from hdbscan) (1.0.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.8/dist-packages (from hdbscan) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from hdbscan) (1.7.3)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.8/dist-packages (from hdbscan) (0.29.32)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from hdbscan) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp38-cp38-linux_x86_64.whl size=2700820 sha256=dbb4019a2da77093eb8a882aa74d04147a0ae14ef30d8f1b7aa5606863cb99e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/06/48/527e038689c581cc9e519c73840efdc7473805149e55bd7ffd\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.29\n"
          ]
        }
      ],
      "source": [
        "!pip install hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVQ0I9rIU4yU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import hdbscan\n",
        "\n",
        "from sklearn.cluster import KMeans, Birch\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "import itertools\n",
        "\n",
        "SEED = 10\n",
        "\n",
        "tf.keras.utils.set_random_seed(1)\n",
        "tf.config.experimental.enable_op_determinism()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmZmsviauZCJ",
        "outputId": "43896c7e-8d22-4007-ad67-b6a163b5c813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvRHJrs5U5R-"
      },
      "outputs": [],
      "source": [
        "\n",
        "porc_unlabel = 0.99\n",
        "x_label, x_unlabel, y_label, y_unlabel = train_test_split(x_train, y_train, test_size=porc_unlabel, random_state=10, stratify=y_train)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adHfi6jVU_Hu",
        "outputId": "111bde96-b4dd-4a13-fb39-bd6e10be3304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3) (10000, 10)\n",
            "(500, 32, 32, 3) (500, 10)\n",
            "(49500, 32, 32, 3) (49500, 10)\n"
          ]
        }
      ],
      "source": [
        "y_fake_label = np.zeros(shape=(len(y_unlabel), 10))\n",
        "\n",
        "print(x_test.shape, y_test.shape)\n",
        "print(x_label.shape, y_label.shape)\n",
        "print(x_unlabel.shape, y_fake_label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdtiWI-6VCr7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# uno etiquetados con no etiquetados\n",
        "\n",
        "# combino etiquetados con los no \n",
        "if x_unlabel.shape[0]>0:\n",
        "  x_train = np.concatenate((x_label, x_unlabel))\n",
        "  y_train = np.concatenate((y_label, y_fake_label))\n",
        "  y_real = np.concatenate((y_label, y_unlabel))\n",
        "else:\n",
        "  x_train = x_label\n",
        "  y_train = y_label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8Abf_MlVsPt",
        "outputId": "1c60112b-93e8-4689-d804-dbf0e7f8d3dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 64, 64, 3)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 512)               14714688  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "cnn_input = tf.keras.Input(shape=(32, 32, 3))\n",
        "upsample = tf.keras.layers.UpSampling2D()(cnn_input)\n",
        "vgg16 = VGG16(include_top=False, weights='imagenet', \n",
        "              pooling='avg', input_shape=(64,64,3))(upsample)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_cnn = keras.models.Model(cnn_input, vgg16)\n",
        "\n",
        "model_cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pj4Nuz2V8dn"
      },
      "outputs": [],
      "source": [
        "def decay(epoch):\n",
        "  \"\"\" This method create the alpha\"\"\"\n",
        "  # returning a very small constant learning rate\n",
        "  return 0.001 / (1 + 1 * 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWS5MZ5rVtjV",
        "outputId": "d5b8e529-642f-4959-f816-b131e4635840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                16416     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,746\n",
            "Trainable params: 16,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 3.2258064516129034e-05.\n",
            "Epoch 1/2\n",
            " 27/391 [=>............................] - ETA: 2:08:51 - loss: 1.7379 - accuracy: 0.0888"
          ]
        }
      ],
      "source": [
        "tf.keras.utils.set_random_seed(1)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "\n",
        "classifier_input = tf.keras.Input(shape=(512,))\n",
        "### ACÁ AGREGAR MAS CAPAS QUE PUDIERAN SER RELEVANTES, SOLO HAY UNA CAPA DE 32\n",
        "classifier_dense2 = tf.keras.layers.Dense(32, activation='relu', kernel_initializer='he_uniform')(classifier_input)\n",
        "classifier_dropout2 = tf.keras.layers.Dropout(0.2)(classifier_dense2)\n",
        "classifier_dense3 = tf.keras.layers.Dense(len(y_train[0]), activation=\"softmax\")(classifier_dropout2)\n",
        "classifier = tf.keras.Model(classifier_input, classifier_dense3, name=\"classifier\")\n",
        "\n",
        "classifier.summary()\n",
        "cnn_classif_input = tf.keras.Input(shape=(32, 32, 3))\n",
        "cnn_series = model_cnn(cnn_classif_input)\n",
        "classif_series = classifier(cnn_series)\n",
        "\n",
        "\n",
        "final_classif = tf.keras.Model(cnn_classif_input, classif_series, name=\"CnnClf\")\n",
        "\n",
        "\n",
        "def my_loss(y_truee, y_pred):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "    l1 = cce(y_truee, y_pred) \n",
        "    mask = tf.reduce_sum(y_truee,axis=1)\n",
        "    mloss = tf.multiply(mask,l1)\n",
        "    mloss = tf.reduce_sum(mloss/tf.math.maximum(tf.reduce_sum(mask),1))\n",
        "    return mloss\n",
        "\n",
        "final_classif.compile(\n",
        "loss = my_loss,\n",
        "optimizer= \"adam\",\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "callback = []\n",
        "callback += [tf.keras.callbacks.LearningRateScheduler(decay, verbose=1)]\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "callback += [es]\n",
        "\n",
        "\n",
        "final_classif.fit(x=x_train, y=y_train,\n",
        "  batch_size=128,\n",
        "  validation_data=(x_test , y_test),\n",
        "  epochs=2, shuffle=True,\n",
        "  callbacks=callback,\n",
        "  verbose=1\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAwneh6YJ4Ns"
      },
      "source": [
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eCztEseJ4Nu"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_RkkIqJJ4Nv"
      },
      "source": [
        "Altoritmos de Clustering a probar:\n",
        "- KMeans: n_clusters\n",
        "- HDBSCAN: ?\n",
        "- BIRCH\n",
        "- K-Medoids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEzn77htpZpD"
      },
      "outputs": [],
      "source": [
        "metrics = ['silhouette_score', 'CH', 'DB']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCUhW-DHJ4Nw"
      },
      "outputs": [],
      "source": [
        "features = model_cnn.predict(x_train)\n",
        "features_test =  model_cnn.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0Abqc-9J4Nx"
      },
      "outputs": [],
      "source": [
        "## Example code\n",
        "#Sil = silhouette_score(X, labels)\n",
        "#CH = calinski_harabasz_score(X, labels)\n",
        "#DB = davies_bouldin_score(X, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0dCSAFcswG-"
      },
      "outputs": [],
      "source": [
        "def eval_cluster(train_data, test_data, pred_labels_train, pred_labels_test, \n",
        "                 metrics = list(zip(metrics,  [silhouette_score, calinski_harabasz_score, davies_bouldin_score]))):\n",
        "  result_dict = {'train_data': {}, 'test_data': {}}\n",
        "  #result_dict['silhouette_score'] = silhouette_score(X, labels)\n",
        "  #result_dict['CH'] = calinski_harabasz_score(X, labels)\n",
        "  #result_dict['DB'] = davies_bouldin_score(X, labels)\n",
        "\n",
        "  # Cartesian Product over the name of the data to evaluate (train/test), the data itself and the metric to evaluate\n",
        "  sample_metric_combination = [element for element in itertools.product(zip(\n",
        "                                                                          ['train_data', 'test_data'],\n",
        "                                                                          [train_data, test_data],\n",
        "                                                                          [pred_labels_train, pred_labels_test]),\n",
        "                                                                        metrics)]\n",
        "\n",
        "  for (sample_name, sample_data, predicted_labels), (metric_name, metric_function) in sample_metric_combination:\n",
        "    result_dict[sample_name][metric_name] = metric_function(sample_data, predicted_labels)\n",
        "  return result_dict\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70iFApn8J4Ny"
      },
      "outputs": [],
      "source": [
        "df_best_results = pd.DataFrame(columns = pd.MultiIndex.from_product([['train_data', 'test_data'], metrics]),\n",
        "                               index = pd.Index(['kmeans', 'birch', 'kmedoids', 'hdbscan'], name  = 'model_name'))\n",
        "df_best_results['model'] = np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHofRJQOJ4Nx"
      },
      "source": [
        "### KMeans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNZEt-2lJ4Nx"
      },
      "source": [
        "\n",
        "n_clusters:\n",
        "- [1,3,5] * N° clases originales\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqUOW-0tWC5G",
        "outputId": "df31dfcb-4a3a-485d-e224-85e91a284c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data - silhouette_score: 0.22556951642036438\n",
            "train_data - CH: 88618.16914808439\n",
            "train_data - DB: 1.2241579082653808\n",
            "test_data - silhouette_score: 0.22456005215644836\n",
            "test_data - CH: 17280.958927438987\n",
            "test_data - DB: 1.2313653971647918\n",
            "train_data - silhouette_score: 0.15953095257282257\n",
            "train_data - CH: 56896.50863840548\n",
            "train_data - DB: 1.4756291984487713\n",
            "test_data - silhouette_score: 0.1580612063407898\n",
            "test_data - CH: 11119.51588933344\n",
            "test_data - DB: 1.4646383282156663\n",
            "train_data - silhouette_score: 0.11288251727819443\n",
            "train_data - CH: 30559.516897189784\n",
            "train_data - DB: 1.6407143071743724\n",
            "test_data - silhouette_score: 0.10980234295129776\n",
            "test_data - CH: 5965.851724277927\n",
            "test_data - DB: 1.6353108115088255\n"
          ]
        }
      ],
      "source": [
        "kmeans_params = ParameterGrid({'n_clusters': [k*y_train.shape[1] for k in [1, 2, 5]]})\n",
        "best_silhouette_kmeans = -1\n",
        "\n",
        "for param in kmeans_params:\n",
        "  k_means = KMeans(**param,random_state=SEED).fit(features)\n",
        "  predict_train = k_means.predict(features)  \n",
        "  predict_test =  k_means.predict(features_test) \n",
        "  results = eval_cluster(train_data = features, test_data = features_test, pred_labels_train = predict_train, pred_labels_test = predict_test)  \n",
        "  \n",
        "  for sample in ['train_data', 'test_data']:\n",
        "    for metric in metrics:\n",
        "      print(f'{sample} - {metric}: {results[sample][metric]}')\n",
        "  \n",
        "    if (sample == 'test_data') and (results['test_data']['silhouette_score'] > best_silhouette_kmeans): # using the silhouette score as the main metric\n",
        "      df_best_results.loc['kmeans', 'model'] = k_means # Only the best model is saved\n",
        "      for metric in metrics: \n",
        "        df_best_results.loc['kmeans', ('test_data', metric)] = results[sample][metric] # Only update metrics if its the best model so far\n",
        "        df_best_results.loc['kmeans', ('train_data', metric)] = results[sample][metric]\n",
        "      best_silhouette_kmeans = results['test_data']['silhouette_score']\n",
        "\n",
        "  #y_kmeans_onehot = to_categorical(predict2, num_classes=k*len(y_train[0])) # pseudo - etiquetas \n",
        "  #y_kmeans_onehot_test = to_categorical(predict_test, num_classes=k*len(y_train[0]))# pseudo - etiquetas  test "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uo7W5Gz8fLc"
      },
      "source": [
        "### BIRCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSg1mV-epwSp"
      },
      "outputs": [],
      "source": [
        "birch_params = ParameterGrid({'n_clusters': [k*y_train.shape[1] for k in [1, 2, 5]], 'threshold':[0.1, 0.5, 1.0, 2.0]})\n",
        "best_silhouette_birch = -1\n",
        "\n",
        "for param in birch_params:\n",
        "  birch = Birch(**param).fit(features)\n",
        "  predict_train = birch.predict(features)  \n",
        "  predict_test =  birch.predict(features_test) \n",
        "  results = eval_cluster(train_data = features, test_data = features_test, pred_labels_train = predict_train, pred_labels_test = predict_test)  \n",
        "  print(param)\n",
        "  for sample in ['train_data', 'test_data']:\n",
        "    for metric in metrics:\n",
        "      print(f'{sample} - {metric}: {results[sample][metric]}')\n",
        "  \n",
        "    if (sample == 'test_data') and (results['test_data']['silhouette_score'] > best_silhouette_birch): # using the silhouette score as the main metric\n",
        "      df_best_results.loc['birch', 'model'] = birch # Only the best model is saved\n",
        "      for metric in metrics: \n",
        "        df_best_results.loc['birch', ('test_data', metric)] = results[sample][metric] # Only update metrics if its the best model so far\n",
        "        df_best_results.loc['birch', ('train_data', metric)] = results[sample][metric]\n",
        "      best_silhouette_birch = results['test_data']['silhouette_score']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnGjnFOwEMjt"
      },
      "source": [
        "### HDBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nzHu9LYuHdQ"
      },
      "outputs": [],
      "source": [
        "import hdbscan\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8s5KcROEO_C"
      },
      "outputs": [],
      "source": [
        "dbscan = hdbscan.HDBSCAN(algorithm='best', alpha=1.0, approx_min_span_tree=True,\n",
        "    gen_min_span_tree=False, leaf_size=40,\n",
        "    metric='euclidean', min_cluster_size=5, min_samples=None, p=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inwyIh5VD9uQ"
      },
      "outputs": [],
      "source": [
        "hdbscan_params = ParameterGrid({'min_cluster_size': [5, 10, 15, 30, 60], 'min_samples':[1, 5, 10, 15, 30],\n",
        "                                'cluster_selection_epsilon': [0, 0.3, 0.5, 0.7], 'cluster_selection_method': ['leaf', 'eom']})\n",
        "best_silhouette_hdbscan = -1\n",
        "\n",
        "for param in hdbscan_params:\n",
        "  dbscan = hdbscan.HDBSCAN(**param).fit(features)\n",
        "  predict_train = hdbscan.approximate_predict(dbscan, features)\n",
        "  predict_test =  hdbscan.approximate_predict(dbscan, features_test)\n",
        "  results = eval_cluster(train_data = features, test_data = features_test, pred_labels_train = predict_train, pred_labels_test = predict_test)  \n",
        "  \n",
        "  for sample in ['train_data', 'test_data']:\n",
        "    for metric in metrics:\n",
        "      print(f'{sample} - {metric}: {results[sample][metric]}')\n",
        "  \n",
        "    if (sample == 'test_data') and (results['test_data']['silhouette_score'] > best_silhouette_hdbscan): # using the silhouette score as the main metric\n",
        "      df_best_results.loc['hdbscan', 'model'] = dbscan # Only the best model is saved\n",
        "      for metric in metrics: \n",
        "        df_best_results.loc['hdbscan', ('test_data', metric)] = results[sample][metric] # Only update metrics if its the best model so far\n",
        "        df_best_results.loc['hdbscan', ('train_data', metric)] = results[sample][metric]\n",
        "      best_silhouette_hdbscan = results['test_data']['silhouette_score']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "gXeN5KcxD9wj",
        "outputId": "e4b9f27f-1b15-409e-dc0d-d40d9a627ded"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cdf04dfd-7fe3-4d63-9002-d54f0f5cda6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">train_data</th>\n",
              "      <th colspan=\"3\" halign=\"left\">test_data</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>silhouette_score</th>\n",
              "      <th>CH</th>\n",
              "      <th>DB</th>\n",
              "      <th>silhouette_score</th>\n",
              "      <th>CH</th>\n",
              "      <th>DB</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>kmeans</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>birch</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>kmedoids</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hdbscan</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdf04dfd-7fe3-4d63-9002-d54f0f5cda6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdf04dfd-7fe3-4d63-9002-d54f0f5cda6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdf04dfd-7fe3-4d63-9002-d54f0f5cda6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 train_data                  test_data           model\n",
              "           silhouette_score   CH   DB silhouette_score   CH   DB      \n",
              "model_name                                                            \n",
              "kmeans                  NaN  NaN  NaN              NaN  NaN  NaN   NaN\n",
              "birch                   NaN  NaN  NaN              NaN  NaN  NaN   NaN\n",
              "kmedoids                NaN  NaN  NaN              NaN  NaN  NaN   NaN\n",
              "hdbscan                 NaN  NaN  NaN              NaN  NaN  NaN   NaN"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "te_df_best_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwSGYMIQD9yT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4aQx3slJ4N0"
      },
      "outputs": [],
      "source": [
        "\n",
        "## GAUSSIAN MIXTURE\n",
        "k_gaussian = GaussianMixture(k*len(y_train[0]), random_state=10).fit(features)\n",
        "predict2 = k_gaussian.predict_proba(features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX6bb3FZJ4N0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6qRS2NHcm-V",
        "outputId": "60a57723-4766-48d6-eaa1-5955edc4f244"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 50)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_kmeans_onehot.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3-wEf0ZJ4N1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}